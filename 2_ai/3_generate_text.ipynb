{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e23dec",
   "metadata": {},
   "source": [
    "# Generazione di Testo con OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb6dd5",
   "metadata": {},
   "source": [
    "## **1. Introduzione alla Generazione di Testo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f074cfe",
   "metadata": {},
   "source": [
    "La generazione di testo con OpenAI permette di ottenere completamenti testuali coerenti e contestualmente rilevanti partendo da un prompt iniziale. Questa funzionalit√† √® utile per:\n",
    "\n",
    "- üìù Completamento automatico di frasi o paragrafi.\n",
    "- ü§ñ Generazione di risposte per chatbot.\n",
    "- ‚úçÔ∏è Creazione di contenuti creativi (storie, poesie, articoli).\n",
    "- üíª Assistenza alla scrittura di codice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224096e",
   "metadata": {},
   "source": [
    "## **2. Endpoint di Completamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a4105",
   "metadata": {},
   "source": [
    "Per generare testo, si utilizza l'endpoint `/v1/completions` dell'API OpenAI. I parametri principali sono:\n",
    "\n",
    "- **`model`**: Il modello da usare (es. `text-davinci-003`).\n",
    "- **`prompt`**: Il testo iniziale che il modello deve completare.\n",
    "- **`max_tokens`**: Il numero massimo di token generabili.\n",
    "- **`temperature`**: Controlla la casualit√† della generazione (0 = pi√π deterministico, 1 = pi√π creativo).\n",
    "- **`top_p`**: Alternativa a `temperature` per il controllo della casualit√†.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0784f",
   "metadata": {},
   "source": [
    "### **Scegliere un Modello per la Generazione di Testo**\n",
    "Quando si invia una richiesta di generazione di testo, la prima decisione da prendere √® **quale modello utilizzare**, poich√© influisce sia sulla qualit√† dell'output che sul costo.\n",
    "\n",
    "#### **Tipologie di Modelli:**\n",
    "- **Modelli di grandi dimensioni (es. GPT-4o)** üèÜ\n",
    "  - Offrono un livello di intelligenza molto elevato e ottime prestazioni.\n",
    "  - Hanno un costo per token pi√π alto.\n",
    "\n",
    "- **Modelli pi√π piccoli (es. GPT-4o-mini)** ‚ö°\n",
    "  - Sono meno avanzati rispetto ai modelli pi√π grandi.\n",
    "  - Sono pi√π veloci e meno costosi per token.\n",
    "\n",
    "- **Modelli per il ragionamento avanzato (es. famiglia o1)** ü§î\n",
    "  - Pi√π lenti a restituire risultati e utilizzano pi√π token per 'pensare'.\n",
    "  - Sono in grado di eseguire ragionamenti avanzati, scrivere codice e pianificare pi√π passaggi.\n",
    "\n",
    "üîπ **Suggerimento**: Sperimenta diversi modelli nel **Playground** per trovare quello che funziona meglio per i tuoi prompt.\n",
    "\n",
    "Il processo per creare prompt efficaci e ottenere risposte di qualit√† dal modello √® chiamato **prompt engineering**.\n",
    "\n",
    "- **Fornire istruzioni precise** üìù\n",
    "- **Includere esempi di output desiderato** üìå\n",
    "- **Aggiungere informazioni di contesto** üìö (soprattutto se non incluse nei dati di addestramento del modello)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b8486",
   "metadata": {},
   "source": [
    "### **Ruoli dei Messaggi nelle API di Chat Completions**\n",
    "\n",
    "Nell'API di completamento chat, i prompt sono strutturati come un **array di messaggi**, ciascuno con un **ruolo** specifico che influenza il modo in cui il modello interpreta l'input.\n",
    "\n",
    "| **Ruolo**       | **Descrizione** | **Esempio d'Uso** |\n",
    "|----------------|---------------|----------------|\n",
    "| **User** üë§ | L'input dell'utente, come se fosse un messaggio in ChatGPT. | *Scrivi un haiku sulla programmazione.* |\n",
    "| **Developer (System Prompt)** üõ† | Istruzioni che hanno la priorit√† sulle richieste dell'utente. | *Rispondi come un assistente esperto di programmazione con un tono formale.* |\n",
    "| **Assistant** ü§ñ | Messaggi generati dal modello, spesso per fornire esempi di output desiderato. | *Fornisci un esempio di barzelletta 'Knock-knock' per migliorare la comprensione del modello.* |\n",
    "\n",
    "üìå **Suggerimento**: L'uso corretto dei ruoli pu√≤ migliorare la qualit√† delle risposte, specialmente quando si desidera che il modello segua istruzioni strutturate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98155c3c",
   "metadata": {},
   "source": [
    "## **3. Installazione e Configurazione**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce50e3ad",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (1.61.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gzile\\pycharmprojects\\corso_python\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef0ed145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY')) # Imposta la chiave come variabile d'ambiente per sicurezza\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11041184",
   "metadata": {},
   "source": [
    "## **4. Esempio di Generazione di Testo in Python**\n",
    "\n",
    "Oltre ai parametri principali, possiamo personalizzare ulteriormente la generazione:\n",
    "\n",
    "- **`n`**: Numero di completamenti generati per ogni prompt.\n",
    "- **`stop`**: Sequenza che interrompe la generazione di testo.\n",
    "- **`presence_penalty`**: Penalizza la ripetizione di argomenti.\n",
    "- **`frequency_penalty`**: Penalizza la ripetizione di frasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6924722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiamo e ritorno,  \n",
      "nel ciclo infinito, vai.  \n",
      "La base attende.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROMPT = \"Scrivi un haiku sulla ricorsione nella programmazione.\"\n",
    "\n",
    "# Un haiku sulla programmazione √® un breve componimento poetico ispirato alla struttura tradizionale giapponese dell‚Äôhaiku \n",
    "# (composto da tre versi con una metrica 5-7-5 sillabe), ma con un tema legato alla programmazione, alla tecnologia o all‚Äôinformatica.\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"developer\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    temperature=1.2, # 1.0 is the default value and represents the model's default behavior of balancing creativity and coherence.\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
